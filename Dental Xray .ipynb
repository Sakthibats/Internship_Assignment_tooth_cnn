{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification of Dental Xray by @Sakthi\n",
    "### Steps\n",
    "1. Import Packages\n",
    "2. Load Data\n",
    "3. Build Model\n",
    "4. Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages\n",
    "#### Importing relevant packages and identifying the necessary folders on computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "Datadir = r\"D:\\Jupy\\xrays database\"\n",
    "Categories = [\"1 root\", \"2 or more roots\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "#### Resize them to the same shape and size in the event they are not all in the same shape or size\n",
    "#### Prepare Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "IMG_SIZE = (130, 230)\n",
    "\n",
    "def create_training_data():\n",
    "    for category in Categories:\n",
    "        path = os.path.join(Datadir, category) #path to images\n",
    "        class_num = Categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, IMG_SIZE)\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data) #shuffles image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= []\n",
    "y= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "X = np.array(X).reshape(-1, 130, 230, 1)\n",
    "y = np.array(y)\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "#### The following combinations of layers yield the best accuracy to loss ratio as analysed on Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1/35 [..............................] - ETA: 0s - loss: 0.7164 - accuracy: 0.3333WARNING:tensorflow:From C:\\Users\\Sakthivel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "35/35 [==============================] - 33s 948ms/step - loss: 3.7286 - accuracy: 0.4563 - val_loss: 0.8024 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.5526 - accuracy: 0.7282 - val_loss: 0.5284 - val_accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 32s 914ms/step - loss: 0.2515 - accuracy: 0.9223 - val_loss: 0.3186 - val_accuracy: 0.9167\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 30s 870ms/step - loss: 0.2335 - accuracy: 0.8932 - val_loss: 0.5293 - val_accuracy: 0.6667\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 31s 881ms/step - loss: 0.2153 - accuracy: 0.9126 - val_loss: 0.1810 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 30s 854ms/step - loss: 0.1653 - accuracy: 0.9223 - val_loss: 0.4115 - val_accuracy: 0.8333\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 32s 902ms/step - loss: 0.1006 - accuracy: 0.9806 - val_loss: 0.1070 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 33s 935ms/step - loss: 0.0735 - accuracy: 0.9515 - val_loss: 0.1251 - val_accuracy: 0.9167\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 31s 897ms/step - loss: 0.0377 - accuracy: 0.9903 - val_loss: 0.1916 - val_accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 33s 939ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "dense_layers = [1]\n",
    "layers_sizes = [128]\n",
    "convo_layers = [1]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layers_size in layers_sizes:\n",
    "        for convo_layer in convo_layers:\n",
    "            Name = \"{}-convo-{}-nodes-{}-dense-{}\".format(convo_layer,layers_size, dense_layer, int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir = 'logs/{}'.format(Name))\n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(layers_size, (3, 3), input_shape = X.shape[1:]))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "            \n",
    "            for l in range(convo_layer-1):\n",
    "                \n",
    "                model.add(Conv2D(layers_size, (3, 3)))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "            \n",
    "            for i in range(dense_layer):\n",
    "                model.add(Dense(layers_size))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(Dropout(0.2))\n",
    "\n",
    "            \n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            model.compile(loss = \"binary_crossentropy\", \n",
    "                         optimizer = \"adam\", \n",
    "                         metrics = ['accuracy'])\n",
    "            \n",
    "            model.fit(X,y, batch_size=3,epochs = 10, validation_split=0.1, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output of model Analysis \n",
    "#### Based on the output the model had an epoch accuracy of roughly 0.9806 and epoch loss of 0.0507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sakthivel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Sakthivel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: tooth.cnn.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('tooth.cnn.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test (For future use)\n",
    "### Create a function to prepare the image for our model and create a method to accept input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"tooth.cnn.model\")\n",
    "\n",
    "#For future folder that will be shared\n",
    "Test_dir = r\"D:\\Jupy\\xrays database\\tester\"\n",
    "\n",
    "testing_imgdata = []\n",
    "testing_catdata = []\n",
    "\n",
    "def test_data():\n",
    "    for category in Categories:\n",
    "        path = os.path.join(Test_dir, category) #path to images\n",
    "        class_num = Categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, IMG_SIZE)\n",
    "                testing_imgdata.append(new_array)\n",
    "                testing_catdata.append(class_num)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "test_data()\n",
    "testing_imgdata = np.array(testing_imgdata).reshape(-1, 130, 230, 1)/255.0\n",
    "testing_catdata = np.array(testing_catdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "prediction= model.predict([testing_imgdata])\n",
    "predicted_val = [int(round(p[0])) for p in prediction]\n",
    "\n",
    "print(\"Confusion Matirx:\\n \", confusion_matrix(testing_catdata, predicted_val))\n",
    "print(\"Classification report:\\n \", classification_report(testing_catdata, predicted_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
